{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/volatile/home/Zaccharie/workspace/understanding-unets\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just to make sure we are using only on CPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                 .|'''|       /.\\      '||'''|,\n",
      "                 ||          // \\\\      ||   ||\n",
      "'||''|, '||  ||` `|'''|,    //...\\\\     ||...|'\n",
      " ||  ||  `|..||   .   ||   //     \\\\    ||\n",
      " ||..|'      ||   |...|' .//       \\\\. .||\n",
      " ||       ,  |'\n",
      ".||        ''\n",
      "\n",
      "Package version: 0.0.3\n",
      "\n",
      "License: CeCILL-B\n",
      "\n",
      "Authors: \n",
      "\n",
      "Antoine Grigis <antoine.grigis@cea.fr>\n",
      "Samuel Farrens <samuel.farrens@cea.fr>\n",
      "Jean-Luc Starck <jl.stark@cea.fr>\n",
      "Philippe Ciuciu <philippe.ciuciu@cea.fr>\n",
      "\n",
      "Dependencies: \n",
      "\n",
      "scipy          : >=1.3.0   - required | 1.3.0     installed\n",
      "numpy          : >=1.16.4  - required | 1.17.4    installed\n",
      "matplotlib     : >=3.0.0   - required | 3.1.0     installed\n",
      "astropy        : >=3.0.0   - required | 3.1.2     installed\n",
      "nibabel        : >=2.3.2   - required | 2.5.1     installed\n",
      "pyqtgraph      : >=0.10.0  - required | 0.10.0    installed\n",
      "progressbar2   : >=3.34.3  - required | ?         installed\n",
      "modopt         : >=1.4.0   - required | 1.4.1     installed\n",
      "scikit-learn   : >=0.19.1  - required | ?         installed\n",
      "pywt           : >=1.0.0   - required | 1.0.3     installed\n",
      "pysparse       : >=0.0.1   - required | ?         installed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib nbagg\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import bm3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from learning_wavelets.data import im_generators, ConcatenateGenerators\n",
    "from learning_wavelets.evaluate import Metrics\n",
    "from learning_wavelets.keras_utils.thresholding import SoftThresholding, HardThresholding\n",
    "from learning_wavelets.learned_wavelet import learned_wavelet, learnlet\n",
    "from learning_wavelets.unet import unet\n",
    "from learning_wavelets.wavelet_denoising import wavelet_denoising_pysap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (9, 5)\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "grey = True\n",
    "n_channels = 3\n",
    "if grey:\n",
    "    n_channels = 1\n",
    "noise_std = 30\n",
    "im_gen_train, im_gen_val, im_gen_test, size, n_samples_train = im_generators(\n",
    "    'bsd68', \n",
    "    batch_size=1, \n",
    "    validation_split=0, \n",
    "    no_augment=True, \n",
    "    noise_std=noise_std,\n",
    "    grey=grey\n",
    ")    \n",
    "im_bsd68 = im_gen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 2*noise_std/255\n",
    "all_net_params = [\n",
    "    {\n",
    "        'name': 'learned wavelet_st',\n",
    "        'init_function': learned_wavelet,\n",
    "        'run_params': {\n",
    "            'n_scales': 5, \n",
    "            'n_details': 256, \n",
    "            'n_coarse': n_channels, \n",
    "            'mixing_details': False,\n",
    "            'denoising_activation': 'linear',\n",
    "            'wav_pooling': True,\n",
    "            'wav_use_bias': False,\n",
    "            'wav_normed': True,\n",
    "            'filters_normed': ['details', 'coarse'],\n",
    "            'input_size': (size, size, n_channels),     \n",
    "        },\n",
    "        'run_id': 'learned_wavelet_div2k_30_1574790444',\n",
    "        'epoch': 250,\n",
    "    },\n",
    "#     {\n",
    "#         'name': 'learned wavelet_ht',\n",
    "#         'init_function': learned_wavelet,\n",
    "#         'run_params': {\n",
    "#             'n_scales': 5, \n",
    "#             'n_details': 256, \n",
    "#             'n_coarse': n_channels, \n",
    "#             'mixing_details': False,\n",
    "#             'denoising_activation': HardThresholding(1.5*thresh),\n",
    "#             'wav_pooling': True,\n",
    "#             'wav_use_bias': False,\n",
    "#             'wav_normed': True,\n",
    "#             'filters_normed': ['details', 'coarse'],\n",
    "#             'input_size': (size, size, n_channels),\n",
    "#         },\n",
    "#         'run_id': 'learned_wavelet_div2k_30_1574371296',\n",
    "#         'epoch': 50,\n",
    "#     },\n",
    "]\n",
    "all_exact_recon_net_params = [\n",
    "    {\n",
    "        'name': 'learnlet_exact_reco',\n",
    "        'init_function': learnlet,\n",
    "        'run_params': {\n",
    "            'denoising_activation': 'linear',\n",
    "            'learnlet_analysis_kwargs':{\n",
    "                'n_tiling': 256, \n",
    "                'mixing_details': False,        \n",
    "            },\n",
    "            'learnlet_synthesis_kwargs':{\n",
    "            },\n",
    "            'n_scales': 5,\n",
    "            'exact_reconstruction_weight': 1,\n",
    "            'input_size': (size, size, n_channels),     \n",
    "        },\n",
    "        'run_id': 'learnlet_div2k_30_1575052510',\n",
    "        'epoch': 250,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_model(init_function=None, run_params=None, run_id=None, epoch=250, **dummy_kwargs):\n",
    "    model = init_function(**run_params)\n",
    "    chkpt_path = f'checkpoints/{run_id}-{epoch}.hdf5'\n",
    "    model.load_weights(chkpt_path)\n",
    "    return model\n",
    "\n",
    "def enumerate_seq(seq, name):\n",
    "    return (seq[i] for i in tqdm_notebook(range(len(seq)), desc=f'Val files for {name}'))\n",
    "\n",
    "def enumerate_seq_noisy(seq, name):\n",
    "    return (np.squeeze(seq[i][0]) for i in tqdm_notebook(range(len(seq)), desc=f'Val files for {name}'))\n",
    "\n",
    "def enumerate_seq_gt(seq):\n",
    "    return (np.squeeze(seq[i][1]) for i in range(len(seq)))\n",
    "\n",
    "def metrics_for_params(reco_function=None, name=None, **net_params):\n",
    "    model = unpack_model(**net_params)\n",
    "    metrics = Metrics()\n",
    "    pred_and_gt = [\n",
    "        (model.predict_on_batch(images_gt), images_gt)\n",
    "        for images_noisy, images_gt in enumerate_seq(im_bsd68, name)\n",
    "    ]    \n",
    "    for im_recos, images in tqdm_notebook(pred_and_gt, desc=f'Stats for {name}'):\n",
    "        metrics.push(images, im_recos.numpy())\n",
    "    return metrics\n",
    "\n",
    "def metrics_exact_recon_net(name=None, **net_params):\n",
    "    model = unpack_model(**net_params)\n",
    "    metrics = Metrics()\n",
    "    pred_and_gt = [\n",
    "        (model.predict_on_batch((images_gt, images_gt))[0], images_gt)\n",
    "        for images_noisy, images_gt in enumerate_seq(im_bsd68, name)\n",
    "    ]    \n",
    "    for im_recos, images in tqdm_notebook(pred_and_gt, desc=f'Stats for {name}'):\n",
    "        metrics.push(images, im_recos.numpy())\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def metrics_wavelets(wavelet_id):\n",
    "    metrics = Metrics()\n",
    "    pred = wavelet_denoising_pysap(\n",
    "        enumerate_seq_noisy(im_bsd68, f'Wavelet denoising {wavelet_id}'),\n",
    "        noise_std=noise_std/255,\n",
    "        wavelet_id=wavelet_id, \n",
    "        n_scales=5, \n",
    "        soft_thresh=False, \n",
    "        n_sigma=3,\n",
    "    )\n",
    "    gt = enumerate_seq_gt(im_bsd68)\n",
    "    for im_recos, images in tqdm_notebook(zip(pred, gt), desc='Stats for wavelet denoising'):\n",
    "        metrics.push(images[..., None], im_recos[..., None])\n",
    "    return metrics\n",
    "\n",
    "def metrics_bm3d():\n",
    "    metrics = Metrics()\n",
    "    pred = [\n",
    "        bm3d.bm3d(image_noisy + 0.5, sigma_psd=noise_std/255, stage_arg=bm3d.BM3DStages.ALL_STAGES) - 0.5\n",
    "        for image_noisy in enumerate_seq_noisy(im_bsd68, f'BM3D')\n",
    "    ]\n",
    "    gt = enumerate_seq_gt(im_bsd68)\n",
    "    for im_recos, images in tqdm_notebook(zip(pred, gt), desc='Stats for bm3d'):\n",
    "        metrics.push(images[..., None], im_recos[..., None])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f4cc9461474162affa6bf2cdf7c957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Val files for learned wavelet_st', max=68, style=ProgressStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01b6a246cfc450f9e373e1326346baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Stats for learned wavelet_st', max=68, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5997059b7b4cc48c90cf625c5845af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Val files for learnlet_exact_reco', max=68, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9dfc715613454fb3b51a110031e922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Stats for learnlet_exact_reco', max=68, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 23min 1s, sys: 6min 47s, total: 29min 48s\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics = []\n",
    "for net_params in all_net_params:\n",
    "    metrics.append((net_params['name'], metrics_for_params(**net_params)))\n",
    "    \n",
    "for net_params in all_exact_recon_net_params:\n",
    "    metrics.append((net_params['name'], metrics_exact_recon_net(**net_params)))\n",
    "    \n",
    "# metrics.append(('bm3d', metrics_bm3d()))\n",
    "# metrics.append(('wavelets_24', metrics_wavelets('24')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('learned wavelet_st', PSNR = 25.56 +/- 5.584 SSIM = 0.8816 +/- 0.06021),\n",
       " ('learnlet_exact_reco', PSNR = 41.48 +/- 4.28 SSIM = 0.991 +/- 0.00542)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.sort(key=lambda x: x[1].metrics['PSNR'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('metrics_net_rec_fastmri', 'wb') as f:\n",
    "#     pickle.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = pd.DataFrame(\n",
    "    index=[name for name, _ in metrics], \n",
    "    columns=['PSNR-mean (std) (dB)', 'SSIM-mean (std)'],\n",
    ")\n",
    "for name, m in metrics:\n",
    "    metrics_table.loc[name, 'PSNR-mean (std) (dB)'] = \"{mean:.4} ({std:.4})\".format(\n",
    "        mean=m.metrics['PSNR'].mean(), \n",
    "        std=m.metrics['PSNR'].stddev(),\n",
    "    )\n",
    "    metrics_table.loc[name, 'SSIM-mean (std)'] = \"{mean:.4} ({std:.4})\".format(\n",
    "        mean=m.metrics['SSIM'].mean(), \n",
    "        std=m.metrics['SSIM'].stddev(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSNR-mean (std) (dB)</th>\n",
       "      <th>SSIM-mean (std)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>learned wavelet_st</td>\n",
       "      <td>25.56 (2.792)</td>\n",
       "      <td>0.8816 (0.03011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>learnlet_exact_reco</td>\n",
       "      <td>41.48 (2.14)</td>\n",
       "      <td>0.991 (0.00271)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    PSNR-mean (std) (dB)   SSIM-mean (std)\n",
       "learned wavelet_st         25.56 (2.792)  0.8816 (0.03011)\n",
       "learnlet_exact_reco         41.48 (2.14)   0.991 (0.00271)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
